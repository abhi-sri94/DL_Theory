{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyzRxrhI7LrO"
      },
      "source": [
        "#Question 1\n",
        "\n",
        "Can you think of a few applications for a sequence-to-sequence RNN? What about a\n",
        "sequence-to-vector RNN, and a vector-to-sequence RNN?\n",
        "\n",
        "................\n",
        "\n",
        "Answer 1 -\n",
        "\n",
        "1) **`Recurrent Neural Networks (RNNs)`** are versatile architectures and can be applied in various domains. Here are some applications for different types of RNNs:\n",
        "\n",
        "1) **Sequence-to-Sequence RNN** :\n",
        "\n",
        "a) `Machine Translation` :\n",
        "\n",
        "- `Problem` : Translate a sequence of words from one language to another.\n",
        "\n",
        "- `Application` : Google Translate and other language translation systems.\n",
        "\n",
        "b) `Speech Recognition` :\n",
        "\n",
        "- `Problem` : Convert a sequence of spoken words into written text.\n",
        "\n",
        "- `Application` : Virtual assistants like Siri or Google Assistant.\n",
        "\n",
        "c) `Video Captioning` :\n",
        "\n",
        "- `Problem` : Generate textual descriptions for sequences of video frames.\n",
        "\n",
        "- `Application` : Automatic video summarization or accessibility for the visually impaired.\n",
        "\n",
        "d) `Text Summarization` :\n",
        "\n",
        "- `Problem` : Summarize a long sequence of text into a shorter version while retaining important information.\n",
        "\n",
        "- `Application` : News article summarization or document summarization.\n",
        "\n",
        "e) `Time Series Prediction` :\n",
        "\n",
        "- `Problem` : Predict the next values in a time series based on historical data.\n",
        "\n",
        "- `Application` : Stock price prediction, weather forecasting.\n",
        "\n",
        "2) **Sequence-to-Vector RNN**:\n",
        "\n",
        "a) `Sentiment Analysis` :\n",
        "\n",
        "- `Problem` : Analyze the sentiment of a sequence of words (e.g., a sentence or a paragraph).\n",
        "\n",
        "- `Application`: Determine sentiment in customer reviews or social media posts.\n",
        "\n",
        "b) `Document Classification` :\n",
        "\n",
        "- `Problem` : Assign a category or label to an entire document.\n",
        "\n",
        "- `Application` : Categorize emails into spam or non-spam, classify news articles.\n",
        "\n",
        "c) `Handwriting Recognition` :\n",
        "\n",
        "- `Problem` : Recognize a sequence of handwritten characters and convert it into text.\n",
        "\n",
        "- `Application` : Digital handwriting recognition systems.\n",
        "\n",
        "3) **Vector-to-Sequence RNN** :\n",
        "\n",
        "a) `Image Captioning` :\n",
        "\n",
        "- `Problem` : Generate a sequence of words describing the content of an image.\n",
        "\n",
        "- `Application` : Describing images for accessibility or generating captions for social media.\n",
        "\n",
        "c) `Music Generation` :\n",
        "\n",
        "- `Problem` : Generate a sequence of musical notes given an initial set of conditions.\n",
        "\n",
        "- `Application` : Algorithmic music composition.\n",
        "\n",
        "d) `Code Generation` :\n",
        "\n",
        "- `Problem` : Convert a vector representation of a programming task into a sequence of code.\n",
        "\n",
        "- `Application` : Automated code generation in software development."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr0dZi2Y-H2T"
      },
      "source": [
        "#Question 2\n",
        "\n",
        "How many dimensions must the inputs of an RNN layer have? What does each dimension represent? What about its outputs?\n",
        "\n",
        "...............\n",
        "\n",
        "Answer 2 -\n",
        "\n",
        "The inputs and outputs of an RNN layer typically have three dimensions: (`batch_size`, `time_steps`, `input_features`) for `inputs` and (`batch_size`, `time_steps`, `output_features`) for `outputs` .\n",
        "\n",
        "**Input Dimensions** :\n",
        "\n",
        "1) `Batch Size (batch_size)` :\n",
        "\n",
        "Represents the number of sequences or samples processed in a batch.\n",
        "\n",
        "2) `Time Steps (time_steps)` :\n",
        "\n",
        "Represents the number of time steps in each sequence.\n",
        "\n",
        "3) `Input Features (input_features)` :\n",
        "\n",
        "Represents the number of features at each time step.\n",
        "\n",
        "For example, if you have a batch of 32 sequences, each with 10 time steps, and each time step has 50 features, the input shape would be (32, 10, 50).\n",
        "\n",
        "**Output Dimensions** :\n",
        "\n",
        "1) `Batch Size (batch_size)` :\n",
        "\n",
        "Same as the input, representing the number of sequences or samples processed in a batch.\n",
        "\n",
        "2) `Time Steps (time_steps)` :\n",
        "\n",
        "Represents the number of time steps in each sequence.\n",
        "\n",
        "3) `Output Features (output_features)` :\n",
        "\n",
        "Represents the number of features in the output at each time step.\n",
        "\n",
        "The output features can be different from the input features, depending on the architecture and task.\n",
        "\n",
        "For example, in many cases, the output features might represent hidden states or encoded features learned by the RNN.\n",
        "\n",
        "The purpose of the time steps dimension is to capture the sequential nature of the input data. The RNN processes each time step in the sequence, and the hidden state at each time step influences the processing of subsequent time steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpgqgGOOORxp"
      },
      "source": [
        "#Question 3\n",
        "\n",
        "If you want to build a deep sequence-to-sequence RNN, which RNN layers should have return_sequences=True? What about a sequence-to-vector RNN?\n",
        "\n",
        "...............\n",
        "\n",
        "Answer 3 -\n",
        "\n",
        "In a deep sequence-to-sequence RNN, you typically set `0return_sequences=True` for all the RNN layers except the last one. This configuration allows each RNN layer to provide output sequences that serve as input for the subsequent layer. The final RNN layer, which outputs the sequence, often has `return_sequences=False` because you usually want a single output for the entire sequence.\n",
        "\n",
        "Here's an example of how you might stack LSTM layers with return_sequences for a deep sequence-to-sequence RNN:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PRBoA0hOquA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First LSTM layer with return_sequences=True\n",
        "model.add(LSTM(units=64, input_shape=(time_steps, input_features), return_sequences=True))\n",
        "\n",
        "# Second LSTM layer with return_sequences=True\n",
        "model.add(LSTM(units=32, return_sequences=True))\n",
        "\n",
        "# Last LSTM layer with return_sequences=False\n",
        "model.add(LSTM(units=16, return_sequences=False))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=output_features, activation='softmax'))\n",
        "\n",
        "# Compile the model and specify loss and optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkeSjBF7Oyid"
      },
      "source": [
        "In contrast, for a sequence-to-vector RNN, you generally set `return_sequences=False` for all layers because you want a single vector output summarizing the entire sequence. Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm2mOT9CP1p7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First LSTM layer with return_sequences=True\n",
        "model.add(LSTM(units=64, input_shape=(time_steps, input_features), return_sequences=False))\n",
        "\n",
        "# Additional LSTM layers with return_sequences=False\n",
        "model.add(LSTM(units=32, return_sequences=False))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=output_features, activation='softmax'))\n",
        "\n",
        "# Compile the model and specify loss and optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDaMU6-qO6qA"
      },
      "source": [
        "#Question 4\n",
        "\n",
        "Suppose you have a daily univariate time series, and you want to forecast the next seven days. Which RNN architecture should you use?\n",
        "\n",
        "..................\n",
        "\n",
        "Answer 4 -\n",
        "\n",
        "For forecasting the next seven days in a daily univariate time series, a suitable RNN architecture is a sequence-to-sequence model where the input sequence consists of historical data, and the output sequence represents the predicted future values. Specifically, you can use a model with multiple layers of recurrent units, such as LSTM (Long Short-Term Memory) or GRU (Gated Recurrent Unit).\n",
        "\n",
        "Here's a simplified example using TensorFlow/Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxOg-rfIQBsC",
        "outputId": "eb4cfe53-855d-44ac-acd7-df56bb5a192d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 10, 64)            17920     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 231       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30567 (119.40 KB)\n",
            "Trainable params: 30567 (119.40 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Assuming `time_steps` is the number of past days considered for prediction\n",
        "# and `input_features` is 1 for a univariate time series.\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Encoder part (processes the historical data)\n",
        "model.add(LSTM(units=64, input_shape=(time_steps, input_features), return_sequences=True))\n",
        "model.add(LSTM(units=32, return_sequences=False))\n",
        "\n",
        "# Decoder part (predicts the next seven days)\n",
        "model.add(Dense(units=7, activation='linear'))\n",
        "\n",
        "# Compile the model and specify loss and optimizer\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Display the model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX26hhDYQHXm"
      },
      "source": [
        "In this example:\n",
        "\n",
        "The encoder processes the historical data with LSTM layers and returns the hidden state from the last time step.\n",
        "\n",
        "The decoder takes this hidden state as input and generates the next seven days of predictions using a dense layer with linear activation (for regression)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9ylK5LeQQgR"
      },
      "source": [
        "#Question 5\n",
        "\n",
        "What are the main difficulties when training RNNs? How can you handle them?\n",
        "\n",
        "...............\n",
        "\n",
        "Answer 5 -\n",
        "\n",
        "Training **Recurrent Neural Networks (RNNs)** comes with several challenges due to the nature of sequential data and the vanishing/exploding gradient problems. Here are some main difficulties when training RNNs and strategies to handle them:\n",
        "\n",
        "1) **Vanishing and Exploding Gradients** :\n",
        "\n",
        "- `Issue` : During backpropagation, gradients can become extremely small (vanishing) or large (exploding), especially when dealing with long sequences. This can lead to difficulties in learning long-term dependencies.\n",
        "\n",
        "- `Handling` : Use architectures with specialized cells designed to mitigate these issues, such as LSTM (Long Short-Term Memory) or GRU (Gated Recurrent Unit). These architectures include mechanisms to selectively update and forget information, helping to address the vanishing gradient problem.\n",
        "\n",
        "2) **Long-Term Dependencies** :\n",
        "\n",
        "- `Issue` : Standard RNNs struggle to capture long-term dependencies due to vanishing gradients. They may not effectively remember information from earlier time steps.\n",
        "\n",
        "- `Handling` : Use architectures like LSTM or GRU, which are explicitly designed to capture long-term dependencies. Additionally, consider using skip connections, attention mechanisms, or more advanced architectures like Transformers for tasks that require capturing distant dependencies.\n",
        "\n",
        "3) **Computational Complexity** :\n",
        "\n",
        "- `Issue` : Training RNNs on long sequences can be computationally expensive and time-consuming.\n",
        "\n",
        "- `Handling` : Consider using truncated backpropagation through time (TBPTT) or use techniques like gradient clipping to avoid exploding gradients. Additionally, optimize your implementation and leverage hardware accelerators (e.g., GPUs) to speed up training.\n",
        "\n",
        "4) **Choice of Architecture and Hyperparameters** :\n",
        "\n",
        "- `Issue` : Selecting the right architecture (number of layers, cell type, etc.) and hyperparameters (learning rate, batch size, etc.) can be challenging and may significantly impact performance.\n",
        "\n",
        "- `Handling` : Experiment with different architectures and hyperparameters using techniques like grid search or random search. Regularize your model with techniques like dropout to prevent overfitting. Monitor training progress and adjust hyperparameters accordingly.\n",
        "\n",
        "5) **Data Preprocessing and Feature Engineering** :\n",
        "\n",
        "- `Issue` : Raw sequential data may require careful preprocessing, handling missing values, normalizing, or scaling.\n",
        "\n",
        "- `Handling` : Preprocess the data appropriately, impute missing values, and scale/normalize the features. Consider using techniques like windowed sequences or sequence augmentation to enhance the model's ability to generalize.\n",
        "\n",
        "6) **Training Time** :\n",
        "\n",
        "- `Issue` : Training RNNs can take a long time, especially for large models or datasets.\n",
        "\n",
        "- `Handling` : Use model checkpoints to save intermediate states during training, enabling you to resume training from a specific point. Monitor training progress and stop training early if the performance plateaus.\n",
        "\n",
        "7) **Overfitting** :\n",
        "\n",
        "- `Issue` : RNNs, especially with a large number of parameters, may be prone to overfitting, particularly on small datasets.\n",
        "\n",
        "- `Handling` : Regularize your model using techniques like dropout or recurrent dropout. Consider using early stopping based on validation performance to prevent overfitting.\n",
        "\n",
        "8) **Gradient Descent Variants** :\n",
        "\n",
        "- `Issue` : Standard gradient descent may not be the most efficient optimizer for RNNs.\n",
        "\n",
        "- `Handling` : Explore advanced optimizers like Adam, RMSprop, or Nadam, which can help overcome issues related to learning rates and converging faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQVEr0l6RXeE"
      },
      "source": [
        "#Question 6\n",
        "\n",
        "Can you sketch the LSTM cellâ€™s architecture?\n",
        "\n",
        "................\n",
        "\n",
        "Answer 6 -\n",
        "\n",
        "The architecture of a Long Short-Term Memory (LSTM) cell is designed to address the vanishing gradient problem in standard recurrent neural networks (RNNs) and facilitate the learning of long-term dependencies in sequential data. The LSTM cell consists of several components, including input, forget, output gates, and a cell state. Here's a sketch of the basic LSTM cell architecture:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K0hpTXJYwTe"
      },
      "outputs": [],
      "source": [
        "          +------------------------+\n",
        "          |                         |\n",
        "          |                         v\n",
        "  +-----------------+         +-----------------+\n",
        "  |                 |         |                 |\n",
        "  |    Input Gate   |         |    Forget Gate  |\n",
        "  |                 |         |                 |\n",
        "  +-----------------+         +-----------------+\n",
        "          |                         ^\n",
        "          v                         |\n",
        "  +-----------------+         +-----------------+\n",
        "  |                 |         |                 |\n",
        "  |   Cell State    |         |   Cell State    |\n",
        "  |                 |         |                 |\n",
        "  +-----------------+         +-----------------+\n",
        "          |                         ^\n",
        "          v                         |\n",
        "  +-----------------+         +-----------------+\n",
        "  |                 |         |                 |\n",
        "  |  Output   Gate |         |  Cell State     |\n",
        "  |                 |         |      Update     |\n",
        "  +-----------------+         +-----------------+\n",
        "          |                         ^\n",
        "          v                         |\n",
        "          +------------------------+\n",
        "                       |\n",
        "                       v\n",
        "               +-----------------+\n",
        "               |                 |\n",
        "               |     Output      |\n",
        "               |                 |\n",
        "               +-----------------+\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agPopp0rYzrk"
      },
      "source": [
        "Here's a brief description of each component:\n",
        "\n",
        "1) `Input Gate` : Determines which values from the input should be updated in the cell state.\n",
        "Computed using the sigmoid activation function.\n",
        "\n",
        "2) `Forget Gate` : Determines which information from the cell state should be discarded or kept.\n",
        "Computed using the sigmoid activation function.\n",
        "\n",
        "3) `Cell State (Memory Cell)` : Represents the long-term memory of the cell.\n",
        "Updated based on the input, forget gate, and cell state update.\n",
        "\n",
        "4) `Output Gate` : Determines the next hidden state based on the updated cell state.\n",
        "Computed using the sigmoid activation function.\n",
        "\n",
        "5) `Output` : Represents the output of the LSTM cell.\n",
        "\n",
        "The key idea behind LSTM is the ability to store information for long durations by selectively updating and forgetting information using the input, forget, and output gates. This architecture helps LSTM cells capture and remember long-term dependencies in sequential data, making them well-suited for tasks like language modeling, machine translation, and time series prediction.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnJYc2KVZMP9"
      },
      "source": [
        "#Question 7\n",
        "\n",
        "Why would you want to use 1D convolutional layers in an RNN?\n",
        "\n",
        "...............\n",
        "\n",
        "Answer 7 -\n",
        "\n",
        "Using 1D convolutional layers in combination with Recurrent Neural Networks (RNNs) can be beneficial for several reasons:\n",
        "\n",
        "1) `Capture Local Patterns` : 1D convolutions are effective in capturing local patterns or dependencies within a sequence. They can identify short-range patterns that might be missed by the recurrent layers alone.\n",
        "\n",
        "2) `Reduce Sequential Processing` : Convolutional layers can help reduce the sequential processing burden on the RNN. By capturing local dependencies with convolutions, the RNN can focus on learning long-term dependencies.\n",
        "\n",
        "3) `Parallelization` : Convolutional layers allow for parallelization of computations across different positions in the sequence. This can lead to faster training times compared to RNNs, which are inherently sequential.\n",
        "\n",
        "4) `Translation Invariance` : 1D convolutions can provide a degree of translation invariance, making the model less sensitive to the exact position of features within a sequence. This can be helpful in tasks where the order of elements is not crucial.\n",
        "\n",
        "5) `Feature Extraction` : Convolutional layers act as feature extractors, automatically learning relevant features from the input sequence. This can help in tasks where identifying important local patterns is essential.\n",
        "\n",
        "6) `Dimensionality Reduction` : Convolutional layers can be followed by pooling layers to reduce the dimensionality of the input sequence, summarizing important information while discarding less relevant details. This can lead to more efficient processing by subsequent RNN layers.\n",
        "\n",
        "7) `Improved Generalization` : Combining convolutional layers with RNNs can enhance the model's ability to generalize across different sequences and capture both local and global dependencies, improving overall performance.\n",
        "\n",
        "8) `Better Handling of Variable-Length Sequences` : Convolutional layers can be particularly useful when dealing with variable-length sequences. They provide a fixed-size representation regardless of the sequence length, making it easier to handle different input sizes.\n",
        "\n",
        "9) `Effective for Multivariate Time Series` : In the context of time series data, 1D convolutions can be applied to multiple channels (features) simultaneously, making them effective for multivariate time series tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gX_rgYQaG4x"
      },
      "source": [
        "#Question 8\n",
        "\n",
        "Which neural network architecture could you use to classify videos?\n",
        "\n",
        "...............\n",
        "\n",
        "Answer 8 -\n",
        "\n",
        "For video classification, you can use Convolutional Neural Networks (CNNs) or a combination of CNNs and Recurrent Neural Networks (RNNs) to effectively capture both spatial and temporal features in videos. Here are two common architectures for video classification:\n",
        "\n",
        "1) **3D Convolutional Networks (3D CNNs)** :\n",
        "\n",
        "a) `Overview` :\n",
        "\n",
        "- 3D CNNs extend the idea of 2D CNNs to three dimensions, allowing them to capture spatial and temporal features simultaneously.\n",
        "\n",
        "- These networks process video data with three-dimensional kernels that move not only spatially across the width and height of each frame but also temporally across the video frames.\n",
        "\n",
        "- 3D CNNs can be applied directly to video frames, treating each frame as a 2D slice in the 3D space.\n",
        "\n",
        "b) `Advantages` :\n",
        "\n",
        "- Effective at capturing both spatial and temporal features in videos.\n",
        "\n",
        "- Directly applies convolutional operations to video data, maintaining the spatial structure.\n",
        "\n",
        "c) `Example Architecture` :\n",
        "\n",
        "- An example 3D CNN architecture might consist of multiple 3D convolutional layers followed by fully connected layers for classification.\n",
        "\n",
        "2) **Two-Stream Networks (Combination of 2D CNNs and RNNs)** :\n",
        "\n",
        "a) `Overview` :\n",
        "\n",
        "- Divide the task into spatial and temporal processing streams.\n",
        "\n",
        "- Spatial stream processes individual video frames using 2D CNNs to capture spatial features.\n",
        "\n",
        "- Temporal stream processes the temporal aspect using RNNs or 1D CNNs to capture the temporal dependencies between frames.\n",
        "\n",
        "b) `Advantages` :\n",
        "\n",
        "- Allows specialized processing for spatial and temporal aspects.\n",
        "\n",
        "- Can be more computationally efficient than 3D CNNs.\n",
        "\n",
        "c) `Example Architecture` :\n",
        "\n",
        "- A common two-stream architecture includes a 2D CNN for spatial processing and an RNN or 1D CNN for temporal processing. The outputs from both streams are combined for final classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zwcr5mgLZJop"
      },
      "outputs": [],
      "source": [
        "            Spatial Stream (2D CNN)\n",
        "            +-------------+\n",
        "            |             |\n",
        "  Video --> | Conv Layer  | --> Global Pooling --> Fully Connected Layer\n",
        "            |             |\n",
        "            +-------------+\n",
        "\n",
        "            Temporal Stream (RNN or 1D CNN)\n",
        "            +-------------+\n",
        "            |             |\n",
        "  Video --> | Recurrent   | --> Fully Connected Layer\n",
        "            | Layer or     |\n",
        "            | 1D Conv      |\n",
        "            +-------------+\n",
        "\n",
        "  Combine the outputs of both streams for final classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsCulvptaXTB"
      },
      "source": [
        "#Question 9\n",
        "\n",
        "Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets.\n",
        "\n",
        "...............\n",
        "\n",
        "Answer 9 -"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "\n",
        "# Load the quickdraw_bitmap split of the SketchRNN dataset\n",
        "data = tfds.load('quickdraw_bitmap', split='train', as_supervised=True)\n",
        "\n",
        "# Convert the dataset to numpy arrays\n",
        "data = tfds.as_numpy(data)\n",
        "\n",
        "# Extract the stroke sequences from the bitmap images\n",
        "inputs = []\n",
        "labels = []\n",
        "for image, label in data:\n",
        "    sequence = tfa.image.rotate(image, 90)  # Rotate the image to align with the SketchRNN format\n",
        "    sequence = tfa.image.flip_left_right(sequence)  # Flip the image to mirror the stroke directions\n",
        "    sequence = np.pad(sequence, ((1, 0), (0, 0), (0, 0)), mode='constant')[:-1]  # Add a starting pen-down stroke\n",
        "    inputs.append(sequence)\n",
        "    labels.append(label)\n",
        "\n",
        "inputs = np.array(inputs)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Define the model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(None, 5)),\n",
        "    tf.keras.layers.LSTM(256),\n",
        "    tf.keras.layers.Dense(345, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(inputs, labels, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_data = tfds.load('quickdraw_bitmap', split='test', as_supervised=True)\n",
        "test_data = tfds.as_numpy(test_data)\n",
        "test_inputs = []\n",
        "test_labels = []\n",
        "for image, label in test_data:\n",
        "    sequence = tfa.image.rotate(image, 90)\n",
        "    sequence = tfa.image.flip_left_right(sequence)\n",
        "    sequence = np.pad(sequence, ((1, 0), (0, 0), (0, 0)), mode='constant')[:-1]\n",
        "    test_inputs.append(sequence)\n",
        "    test_labels.append(label)\n",
        "\n",
        "test_inputs = np.array(test_inputs)\n",
        "test_labels = np.array(test_labels)\n",
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_labels, batch_size=32)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "metadata": {
        "id": "YFz93LAZbMFK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}