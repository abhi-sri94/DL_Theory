{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1\n",
        "\n",
        "How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n",
        "\n",
        "...............\n",
        "\n",
        "Answer 1 -\n",
        "\n",
        "TensorFlow is an open-source deep learning framework developed by Google that provides a flexible and comprehensive ecosystem for building, training, and deploying machine learning models.\n",
        "Its main features include a high-level Keras API for rapid prototyping, support for both CPU and GPU acceleration, distributed computing capabilities, and extensive pre-built model architectures.\n",
        "Other popular deep learning libraries include PyTorch, Keras, Caffe, and MXNet."
      ],
      "metadata": {
        "id": "Q6oK6ZaNVdtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2\n",
        "\n",
        "Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
        "\n",
        "..............\n",
        "\n",
        "Answer 2 -\n",
        "\n",
        "`TensorFlow` and `NumPy` serve different primary purposes, and while there is some overlap in functionality, TensorFlow is not a drop-in replacement for NumPy. Here are the main differences between the two:\n",
        "\n",
        "1) **Purpose** :\n",
        "\n",
        "- `TensorFlow` : TensorFlow is primarily designed for building and training deep learning models, including neural networks and other machine learning algorithms. It focuses on efficiently performing mathematical operations on large tensors and offers automatic differentiation for gradient-based optimization.\n",
        "\n",
        "- `NumPy` : NumPy is a fundamental library for numerical computing in Python. It provides support for working with multi-dimensional arrays, matrices, and a wide range of mathematical functions. While it can be used for scientific and data analysis tasks, it does not specialize in deep learning.\n",
        "\n",
        "2) **Computation Graph vs. Eager Execution** :\n",
        "\n",
        "- `TensorFlow` : TensorFlow uses a computation graph paradigm. You define a computation graph first and then run it within a TensorFlow session. This allows for optimizations and distributed computing. TensorFlow 2.0 and later versions also support eager execution, which is similar to how NumPy operates, enabling more interactive development.\n",
        "\n",
        "- `NumPy` : NumPy operates in an eager execution mode by default. You can perform computations immediately and interactively without the need to define a computation graph. This makes NumPy well-suited for interactive data exploration and quick prototyping.\n",
        "\n",
        "3) **Deep Learning** :\n",
        "\n",
        "- `TensorFlow` : TensorFlow provides a comprehensive deep learning framework, including high-level APIs like Keras. It offers built-in tools for defining, training, and deploying deep neural networks.\n",
        "\n",
        "- `NumPy` : NumPy does not have built-in support for deep learning. While you can use it to build neural networks from scratch, it lacks specialized tools and optimizations for deep learning tasks.\n",
        "\n",
        "4) **GPU Acceleration** :\n",
        "\n",
        "- `TensorFlow` : TensorFlow provides seamless GPU acceleration, making it suitable for training deep learning models on GPUs, which is essential for performance-critical tasks.\n",
        "\n",
        "- `NumPy` : NumPy does not natively support GPU acceleration, so you would need to rely on additional libraries or frameworks like CuPy to achieve GPU acceleration for numerical computations.\n",
        "\n",
        "5) **Community and Ecosystem** :\n",
        "\n",
        "- `TensorFlow` : TensorFlow has a large and active community, extensive documentation, and a rich ecosystem of pre-built models and tools for various machine learning tasks.\n",
        "\n",
        "- `NumPy` : NumPy is widely used in the scientific and data analysis communities, with a vast array of packages and libraries built on top of it, such as SciPy and scikit-learn."
      ],
      "metadata": {
        "id": "AK98nhWiV_rB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3\n",
        "\n",
        "Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?\n",
        "\n",
        "..............\n",
        "\n",
        "Answer 3 -\n",
        "\n",
        "Yes, you would generally get the same result when using `tf.range(10)` and `tf.constant(np.arange(10))` . Both of these constructs are used to create tensors representing a range of values from 0 to 9.\n",
        "\n",
        "Here's a breakdown of each:\n",
        "\n",
        "1) **tf.range(10)** : This function generates a tensor with values ranging from 0 to 9 (i.e., 10 values in total). It is a TensorFlow-specific way of creating a sequence of numbers within a specified range. The resulting tensor will have a dtype of `tf.int32` by default unless you specify a different dtype.\n",
        "\n",
        "2) **tf.constant(np.arange(10))** : In this case, you are using NumPy's `np.arange(10)` to create a NumPy array representing the same sequence of numbers from 0 to 9. Then, you convert this NumPy array to a TensorFlow constant tensor using `tf.constant()` . The resulting tensor will also have a dtype of tf.int32 by default.\n",
        "\n",
        "In most practical cases, the values and types of the tensors created using these two approaches will be the same. However, you can explicitly set the dtype when using tf.constant() to ensure they match if needed. For example:"
      ],
      "metadata": {
        "id": "QFLBINnaXcQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(np.arange(10), dtype=tf.int32)  # Explicitly set dtype to match tf.range"
      ],
      "metadata": {
        "id": "COrCFKLhb9lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4\n",
        "\n",
        "Can you name six other data structures available in TensorFlow, beyond regular tensors?\n",
        "\n",
        "..............\n",
        "\n",
        "Answer 4 -\n",
        "\n",
        "Beyond regular tensors, TensorFlow provides several other data structures and components for various machine learning and deep learning tasks. Here are six of them:\n",
        "\n",
        "1) **Sparse Tensors** : Sparse tensors are used to represent tensors with a large number of elements that are mostly zero. TensorFlow's `tf.sparse` module provides support for operations on these tensors, which can be more memory-efficient for sparse data.\n",
        "\n",
        "2) **Ragged Tensors** : Ragged tensors are used to represent data with varying lengths, such as sequences of different lengths in natural language processing tasks. They are part of TensorFlow's `tf.ragged` module and are useful for handling data that cannot be easily represented as regular tensors.\n",
        "\n",
        "3) **Tensor Arrays** : `tf.TensorArray` is a dynamic data structure that can be used to store tensors of varying shapes and sizes. It is particularly useful when dealing with dynamic computation graphs or sequences of tensors.\n",
        "\n",
        "4) **Queues and Dataset API** : TensorFlow provides mechanisms for building data input pipelines using queues and the `tf.data` API. These structures are used to efficiently load and preprocess data for training deep learning models, and they are essential for handling large datasets.\n",
        "\n",
        "5) **Variable** : While not exactly a data structure, TensorFlow's `tf.Variable` is a special type of tensor that is typically used to represent model parameters that need to be learned during training. Variables can be updated during training using gradients computed by optimizers.\n",
        "\n",
        "6) **Sparse Feature Columns** : In the context of TensorFlow's Estimators (a high-level API for building and training machine learning models), sparse feature columns are used to work with sparse input data, such as categorical features. They allow you to efficiently represent and process sparse features in your models."
      ],
      "metadata": {
        "id": "hPOeW-3ZcA41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5\n",
        "\n",
        "A custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?\n",
        "\n",
        "..............\n",
        "\n",
        "Answer 5 -\n",
        "\n",
        "In TensorFlow and Keras, you can define custom loss functions using either of the following two approaches: writing a function or subclassing the keras.losses.Loss class. The choice between these options depends on your specific use case and requirements:\n",
        "\n",
        "1) **Writing a Function** :\n",
        "\n",
        "- `When to Use` : Writing a custom loss function as a Python function is a more straightforward and lightweight approach. You should use this option when your loss function is relatively simple and can be expressed as a mathematical formula using TensorFlow operations.\n",
        "\n",
        "- `Advantages` : Simplicity and ease of use. It's a quick way to define a loss function for simple tasks.\n",
        "\n",
        "Example:\n"
      ],
      "metadata": {
        "id": "Er2Mc9jstIxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # Define your custom loss computation here using TensorFlow operations\n",
        "    loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "PD98lAKotiEk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) **Subclassing keras.losses.Loss Class** :\n",
        "\n",
        "- `When to Use` : Subclassing the keras.losses.Loss class is more appropriate when you need to implement a complex or custom loss function that involves additional logic or non-trivial computations beyond a simple mathematical formula. It provides greater flexibility for defining custom behavior.\n",
        "\n",
        "- `Advantages` : Allows you to encapsulate complex loss computations, potentially involving custom gradients or additional parameters, within a class. It is more suitable for advanced use cases.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "YtDSWLl3to4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class CustomLoss(keras.losses.Loss):\n",
        "    def __init__(self, regularization_factor=0.01, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.regularization_factor = regularization_factor\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # Define your custom loss computation here, including regularization\n",
        "        loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "        regularization_loss = self.regularization_factor * tf.reduce_sum(self.losses)\n",
        "        return loss + regularization_loss"
      ],
      "metadata": {
        "id": "VHQKVQNztk3T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 6\n",
        "\n",
        "Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric.\n",
        "When would you use each option?\n",
        "\n",
        "...............\n",
        "\n",
        "Answer 6 -\n",
        "\n",
        "In TensorFlow and Keras, you can define custom metrics using either a standalone function or by subclassing the keras.metrics.Metric class. The choice between these two options depends on your specific requirements and the complexity of the metric you want to define:\n",
        "\n",
        "1) **Defining a Custom Metric Function** :\n",
        "\n",
        "- `When to Use` : Writing a custom metric function is a suitable choice when you have a straightforward metric that can be expressed as a mathematical operation on the model's predictions and the true labels. For simple metrics, this approach is more concise and easier to implement.\n",
        "\n",
        "- `Advantages` : Simplicity and ease of use for basic metrics.\n",
        "\n",
        "Example:\n"
      ],
      "metadata": {
        "id": "IwYg8lLgt9SY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def custom_metric(y_true, y_pred):\n",
        "    # Define your custom metric computation here using TensorFlow operations\n",
        "    metric_value = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
        "    return metric_value"
      ],
      "metadata": {
        "id": "Nhx2HSsMt3dG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) **Subclassing keras.metrics.Metric Class** :\n",
        "\n",
        "- `When to Use` : Subclassing the keras.metrics.Metric class is more appropriate when you need to implement a complex or custom metric that involves additional logic, stateful computations (e.g., moving averages), or non-trivial aggregation of values across batches. It offers greater flexibility for advanced metrics.\n",
        "\n",
        "- `Advantages` : Allows you to encapsulate complex metric computations within a class, making it easier to manage metric state and incorporate custom logic.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "lgnRKe3supfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class CustomMetric(keras.metrics.Metric):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # Define your custom metric update logic here\n",
        "        metric_value = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
        "        self.total.assign_add(tf.reduce_sum(metric_value))\n",
        "        self.count.assign_add(tf.cast(tf.shape(y_true)[0], tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        return self.total / self.count"
      ],
      "metadata": {
        "id": "FsPPdsDPun9t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 7\n",
        "\n",
        "When should you create a custom layer versus a custom model?\n",
        "\n",
        "..............\n",
        "\n",
        "Answer 7 -\n",
        "\n",
        "In TensorFlow Keras, custom layers and custom models serve different purposes and are used in different contexts. Here are some general guidelines:\n",
        "\n",
        "1) **Custom Layers** : If you want to define a new type of layer that can be used within an existing model architecture, you should create a custom layer. Custom layers can be used to implement new types of neural network operations or to modify the behavior of existing layers. Examples of custom layers include activation layers, normalization layers, and attention layers.\n",
        "\n",
        "2) **Custom Models** : If you want to define a new type of model architecture that is not easily expressible using existing layers and models, you should create a custom model. Custom models can be used to implement novel neural network architectures, such as those involving multiple inputs or outputs, or those with custom training loops or loss functions. Examples of custom models include multi-input models, multi-output models, and reinforcement learning models."
      ],
      "metadata": {
        "id": "ofbKHPSSu9oZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 8\n",
        "\n",
        "What are some use cases that require writing your own custom training loop?\n",
        "\n",
        "..............\n",
        "\n",
        "Answer 8 -\n",
        "\n",
        "Writing your own custom training loop in deep learning is necessary for certain advanced use cases where you need fine-grained control over the training process or when you want to implement custom training algorithms. Here are some common use cases that may require writing a custom training loop:\n",
        "\n",
        "1) **Research and Experimentation** : When conducting research in machine learning, you might need to experiment with novel training algorithms, loss functions, or optimization techniques that are not readily available in standard libraries. Custom training loops allow you to implement and test these custom components.\n",
        "\n",
        "2) **Advanced Optimization Techniques** : Some optimization techniques, such as meta-learning, curriculum learning, or reinforcement learning with custom reward functions, may require custom training loops to implement the specialized training procedures involved.\n",
        "\n",
        "3) **Gated Learning** : When you want to apply different learning rates, optimizers, or loss functions to different parts of a neural network or layers at different stages of training (e.g., layer-wise pretraining), a custom training loop allows you to implement these variations.\n",
        "\n",
        "4) **Custom Data Augmentation** : If your data augmentation strategies are complex or depend on dynamic conditions, a custom training loop allows you to apply data augmentation at runtime, possibly with adaptive parameters based on the training progress.\n",
        "\n",
        "5) **Handling Non-Standard Data Inputs** : When working with unconventional data sources, such as sensor data or sequential data with unusual structures, custom training loops provide the flexibility to preprocess and input the data appropriately for your model.\n",
        "\n",
        "6) **Complex Evaluation Metrics** : If you need to compute and track complex evaluation metrics that are not covered by standard loss functions or metrics, a custom training loop allows you to calculate and update these metrics during training.\n",
        "\n",
        "7) **Active Learning** : In active learning scenarios, where the model interacts with an external environment or human annotators to select and label training examples, a custom training loop enables you to orchestrate this interaction.\n",
        "\n",
        "8) **Low-Level Debugging and Monitoring** : Writing your training loop can help you gain deeper insights into model behavior and troubleshoot issues by adding custom debugging and monitoring logic during training.\n",
        "\n",
        "9) **Distributed or Parallel Training** : In distributed deep learning setups where you're training on multiple GPUs or across multiple machines, custom training loops provide the flexibility to manage data distribution, synchronization, and gradient aggregation.\n",
        "\n",
        "10) **Resource Constraints** : When you need to manage resource constraints, such as memory limitations or training on edge devices, custom training loops allow you to optimize memory usage and model checkpointing strategies."
      ],
      "metadata": {
        "id": "T87cRW1fvX3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 9\n",
        "\n",
        "Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?\n",
        "\n",
        "...............\n",
        "\n",
        "Answer 9 -\n",
        "\n",
        "In TensorFlow Keras, custom components such as layers, models, loss functions, and metrics can contain arbitrary Python code, but they must be convertible to TensorFlow Functions in order to be used in a computational graph. TensorFlow Functions are a special type of callable that can be traced by TensorFlow's autograph system, allowing them to be used in accelerated computational graphs for improved performance.\n",
        "\n",
        "When defining custom components in TensorFlow Keras, it is generally a good idea to follow the conventions and best practices outlined in the TensorFlow documentation in order to ensure that the components are compatible with TensorFlow's autograph system. This may involve using special decorators such as `@tf.function` to convert Python functions to TensorFlow Functions, or using other TensorFlow-specific constructs such as `tf.Variable` to define trainable variables.\n",
        "\n",
        "However, it is also possible to include arbitrary Python code in custom Keras components, as long as the code does not conflict with the requirements of the TensorFlow runtime. For example, you may be able to use standard Python control flow constructs such as if statements and loops in your code, but you may need to use TensorFlow-specific constructs such as `tf.cond` or `tf.while_loop` in order to ensure that the code can be traced by autograph and included in a computational graph."
      ],
      "metadata": {
        "id": "u-reY-jp03OI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 10\n",
        "\n",
        "What are the main rules to respect if you want a function to be convertible to a TF Function?\n",
        "\n",
        "................\n",
        "\n",
        "Answer 10 -\n",
        "\n",
        "To ensure that a Python function can be successfully converted to a TensorFlow Function (TF Function), which allows for graph optimization and execution, you should follow several rules and guidelines:\n",
        "\n",
        "1) **Use TensorFlow Operations (`tf.*`)** : The primary rule is to use TensorFlow operations (`tf.*`) for all mathematical computations within the function. TensorFlow can only optimize and convert operations it recognizes as part of its computational graph. Avoid using standard Python operations like `+` , `-` , `*` , `/` , and instead use their TensorFlow equivalents (`tf.add` , `tf.subtract` , `tf.multiply` , `tf.divide`) to perform mathematical operations.\n",
        "\n",
        "2) **Avoid Python Control Flow** : Limit or avoid Python control flow statements (e.g., `if` , `for` , `while`) within the function. TensorFlow's graph execution relies on static graphs, so dynamic Python control flow can be challenging to convert. Instead, use TensorFlow control flow operations like `tf.cond` , `tf.while_loop` , and `tf.where` when necessary.\n",
        "\n",
        "3) **No External Dependencies** : Ensure that the function does not rely on external Python dependencies that are not TensorFlow-compatible. External dependencies can disrupt graph compilation and execution.\n",
        "\n",
        "4) **Minimize Side Effects** : TF Functions should be deterministic, so minimize or eliminate any side effects within the function, such as modifying global variables or state outside of TensorFlow variables.\n",
        "\n",
        "5) **Avoid Defining Variables Inside Functions** : While you can define TensorFlow variables inside a function, it's generally recommended to define them outside the function and pass them as arguments. This ensures variable sharing between function calls.\n",
        "\n",
        "6) **Use TensorFlow Data Types** : Use TensorFlow data types (`tf.float32` , `tf.int32` , etc.) for tensor elements rather than Python data types (`float` , `int` , etc.). TensorFlow functions are more robust when data types are explicitly specified.\n",
        "\n",
        "7) **Avoid Using `print()`** : Remove or comment out any **print()** statements within the function. Printing can disrupt graph compilation and is generally not supported within TF Functions.\n",
        "\n",
        "8) **Decorate with `@tf.function`** : Explicitly decorate the function with the `@tf.function` decorator. This decorator signals TensorFlow to compile and optimize the function as a TF Function. However, note that not all functions need to be converted to TF Functions; use it selectively where performance benefits are essential.\n",
        "\n",
        "Here's an example of a Python function adhering to these rules:"
      ],
      "metadata": {
        "id": "i-6hoTOhSvWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def custom_tf_function(input_tensor):\n",
        "    # Use TensorFlow operations\n",
        "    result = tf.reduce_sum(tf.square(input_tensor))\n",
        "    return result\n",
        "\n",
        "# Usage:\n",
        "input_data = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)\n",
        "output = custom_tf_function(input_data)"
      ],
      "metadata": {
        "id": "ZB28FfI-ouVh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 11\n",
        "\n",
        "When would you need to create a dynamic Keras model? How do you do that? Why not\n",
        "make all your models dynamic?\n",
        "\n",
        ".................\n",
        "\n",
        "Answer 11 -\n",
        "\n",
        "You would need to create a dynamic Keras model when the shape or size of your inputs and/or outputs is not fixed at the time of model construction. This could occur in several scenarios, such as:\n",
        "\n",
        "- When working with variable-length sequences of data, such as text or time series data.\n",
        "\n",
        "- When dealing with images or other data types where the dimensions of the input may vary, such as using data augmentation techniques.\n",
        "\n",
        "- When using certain types of advanced architectures, such as attention mechanisms or recursive neural networks.\n",
        "\n",
        "In order to create a dynamic Keras model, you need to specify the input shape of your model as None for any dimensions that may vary in size. For example, if you were working with sequences of text data, you could define a dynamic Keras model as follows"
      ],
      "metadata": {
        "id": "51yrBSqZox7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "x = keras.layers.Embedding(input_dim=1000, output_dim=16)(inputs)\n",
        "x = keras.layers.LSTM(32)(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "zKEZBShfpMuY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the input shape of the model is defined as (None,), which allows for variable-length sequences of integer data to be passed in as inputs.\n",
        "\n",
        "It is not always necessary or desirable to make all models dynamic, as there can be some performance benefits to using static models with fixed input and output shapes. Static models can be optimized more effectively by the TensorFlow compiler, and can take advantage of hardware-specific optimizations such as fused operations.\n",
        "\n",
        "However, in cases where you need to work with variable-length or dynamically shaped data, or when using certain types of advanced architectures, a dynamic Keras model may be necessary to achieve the desired results. In these cases, it is important to follow best practices and ensure that your model is well-designed and efficient, in order to achieve good performance and scalability."
      ],
      "metadata": {
        "id": "pOvsIzP5pkX4"
      }
    }
  ]
}